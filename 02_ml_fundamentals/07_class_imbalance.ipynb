{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Class Imbalance\n",
        "\n",
        "This notebook is a **companion to `07_class_imbalance.md`**.\n",
        "\n",
        "Purpose:\n",
        "- Illustrate why accuracy fails\n",
        "- Compare metrics under imbalance\n",
        "- Reinforce interview intuition\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulated Imbalanced Dataset\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "n = 1000\n",
        "y_true = np.random.choice([0, 1], size=n, p=[0.95, 0.05])\n",
        "\n",
        "# Naive model predicts all zeros\n",
        "y_pred_naive = np.zeros_like(y_true)\n",
        "\n",
        "pd.Series(y_true).value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Naive Model Performance\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "pd.DataFrame({\n",
        "    'Accuracy': [accuracy_score(y_true, y_pred_naive)],\n",
        "    'Precision': [precision_score(y_true, y_pred_naive, zero_division=0)],\n",
        "    'Recall': [recall_score(y_true, y_pred_naive)],\n",
        "    'F1': [f1_score(y_true, y_pred_naive)]\n",
        "}).T.rename(columns={0: 'Value'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true, y_pred_naive)\n",
        "pd.DataFrame(cm, index=['Actual 0', 'Actual 1'], columns=['Pred 0', 'Pred 1'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interview Takeaways\n",
        "\n",
        "- High accuracy can be meaningless\n",
        "- Minority class performance matters most\n",
        "- Metrics must reflect business cost\n",
        "\n",
        "In interviews, always ask about base rates.\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
